use_mock: false  # Set to true to use mock vLLM for debugging (no GPU required)

mm_encoder_tp_mode: "data"
mm_processor_cache_gb: 0
seed: 0
dtype: "bfloat16"
gpu_memory_utilization: 0.9
mm_processor_kwargs:
  do_resize: true
  size:
    shortest_edge: 524288 # 256
    longest_edge: 33554432 # 16384*32*32*2
limit_mm_per_prompt:
  image: 0
  video: 1

enable_expert_parallel: false  # Set to true for MoE models

tensor_parallel_size: null # use all GPUs by default
